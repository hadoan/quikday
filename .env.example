# ============================================================================
# Backend Configuration
# ============================================================================
WEBAPP_URL=http://localhost:3000

# ============================================================================
# Frontend Configuration (Vite)
# ============================================================================

# Data Source: 'mock' (default) or 'live'
# - mock: Use MockDataSource with existing mock data (no backend required)
# - live: Use ApiDataSource to call REST/WebSocket endpoints
# Can be overridden at runtime via query param: ?ds=live or ?ds=mock
VITE_DATA_SOURCE=mock

# API Base URL (for REST calls)
# Default: http://localhost:3000
VITE_API_BASE_URL=http://localhost:3000

# WebSocket Base URL (for real-time updates)
# Default: ws://localhost:3000
VITE_WS_BASE_URL=ws://localhost:3000

# ============================================================================
# Integration Credentials
# ============================================================================
LINKEDIN_CLIENT_ID=
LINKEDIN_CLIENT_SECRET=
LINKEDIN_SCOPES=r_liteprofile r_emailaddress w_member_social

GMAIL_CLIENT_ID=
GMAIL_CLIENT_SECRET=
GMAIL_SCOPES=https://www.googleapis.com/auth/gmail.readonly

# ============================================================================
# AI / LLM Configuration
# ============================================================================
# LLM Provider: 'openai', 'azure', or 'anthropic'
# - openai: Use regular OpenAI API (GPT-4, GPT-4o, etc.)
# - azure: Use Azure OpenAI Service
# - anthropic: Use Anthropic Claude API (Claude 3.5 Sonnet, Haiku, etc.)
LLM_PROVIDER=openai

# OpenAI Configuration (used when LLM_PROVIDER=openai)
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4o

# Azure OpenAI Configuration (used when LLM_PROVIDER=azure)
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_VERSION=2024-08-01-preview
AZURE_OPENAI_DEPLOYMENT=gpt-4o

# Anthropic Configuration (used when LLM_PROVIDER=anthropic)
ANTHROPIC_API_KEY=
# Supported models: claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022, etc.
ANTHROPIC_MODEL=claude-3-5-haiku-20241022

# Planner Model Override (Optional, works with any provider)
# Use a stronger/different model specifically for planning tasks
# Examples: 
#   - OpenAI: gpt-4o, gpt-4-turbo, gpt-4
#   - Anthropic: claude-3-5-sonnet-20241022, claude-3-opus-20240229
#   - Azure: your-deployment-name
# PLANNER_MODEL=

# Legacy: Set to 'true' to use Azure OpenAI (overrides LLM_PROVIDER if set)
# Deprecated: Use LLM_PROVIDER=azure instead
USE_AZURE_OPENAI=false

# ============================================================================
# Observability (Langfuse)
# ============================================================================
# Set to enable prompt/response logging to Langfuse
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
# Optional; e.g., https://cloud.langfuse.com or self-hosted base URL
LANGFUSE_HOST=

# ============================================================================
# Feature Flags (Runtime Override via Query Params)
# ============================================================================
# ?ds=live|mock - Switch data source
# ?ff=live-approvals,live-undo,debug - Enable features
# Example: http://localhost:5173?ds=live&ff=debug
